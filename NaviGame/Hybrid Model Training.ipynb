{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from reinforcement_training import *\n",
    "from notebook_game_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets train a DQN model!\n",
    "# make the model\n",
    "hiddens = [{\"size\":20,\"activation\":\"relu\"},\n",
    "           {\"size\":20,\"activation\":\"relu\"}]\n",
    "#            {\"size\":100,\"activation\":\"relu\"},\n",
    "#           {\"size\":100,\"activation\":\"relu\"}]\n",
    "# make an optimizer\n",
    "from keras.optimizers import sgd, RMSprop, Adagrad, Adadelta, Adam\n",
    "# note to self: DON'T CHANGE THIS UNTIL YOU KNOW WE'RE LEARNING SOMETHING\n",
    "# optimizer = sgd(lr = 0.0001)\n",
    "# optimizer_str = \"SGD\"\n",
    "# optimizer = Adagrad()\n",
    "# optimizer_str = \"Adagrad\"\n",
    "# optimizer = RMSprop()\n",
    "# optimizer_str = \"RMSprop\"\n",
    "# optimizer = Adadelta()\n",
    "# optimizer_str = \"Adadelta\"\n",
    "optimizer = Adam()\n",
    "optimizer_str = \"Adam\"\n",
    "model = baseline_model(optimizer, hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/squalor/Documents/DSi Repos/capstone repos/Python.Swarms/navi_game.py(43)setup()\n",
      "-> self.Flag.strategy.placeIt(y = self.goal[0], x = self.goal[1])\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "# prepare the game for training model\n",
    "training_game_size = 9\n",
    "training_game = HybridNaviGame(training_game_size,\n",
    "                                training_game_size,\n",
    "                                model = model)\n",
    "training_game.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 34029, Replay Loss: 0.358:  34%|███▍      | 34030/100000 [18:50<29:54, 36.77it/s]]    "
     ]
    }
   ],
   "source": [
    "training_episodes = 100000\n",
    "steps = 10\n",
    "# train the model\n",
    "output = train_model(game = training_game,\n",
    "                model = model,\n",
    "                episodes = training_episodes,\n",
    "                steps = steps,\n",
    "                e_start = .9,\n",
    "                e_stop = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot learning info\n",
    "title_str = str(training_game_size) + \"x\" + str(training_game_size) + \" with \" \n",
    "title_str += str(training_episodes) + \" episodes, \" + str(steps) + \" steps per episode, & \"\n",
    "title_str += str(len(hiddens)) + \" hidden layers, optimized with \" + optimizer_str + \"\\n\"\n",
    "f, axarr = pl.subplots(3, 1, figsize = (10, 15), dpi = 300)\n",
    "# f.canvas.set_window_title(\"RL Loss, 100 eps w/ 50 steps, Look: 20\")\n",
    "mean_step = 10\n",
    "num_means = int(len(output['distances'])/mean_step/steps)\n",
    "\n",
    "for _, k in enumerate([1000, 5000, 10000]):\n",
    "    mean_step = k\n",
    "    mean_rewards = []\n",
    "    mean_dists = []\n",
    "    mean_loss = []\n",
    "    num_means = int(len(output['distances'])/mean_step/steps)\n",
    "    steps_per_mean = steps*mean_step\n",
    "    x = np.linspace(0, training_episodes, num_means)\n",
    "    for i in range(num_means):\n",
    "        mean_r = 0\n",
    "        mean_d = 0\n",
    "        mean_l = 0\n",
    "        for j in range(steps_per_mean):\n",
    "            mean_r += output['rewards'][j + i * steps_per_mean]\n",
    "            mean_d += output['distances'][j + i * steps_per_mean]\n",
    "            mean_l += output['loss'][j + i * steps_per_mean]\n",
    "        mean_r = mean_r / steps_per_mean\n",
    "        mean_d = mean_d / steps_per_mean\n",
    "        mean_l = mean_l / steps_per_mean\n",
    "        mean_rewards.append(mean_r)\n",
    "        mean_dists.append(mean_d)\n",
    "        mean_loss.append(mean_l)\n",
    "    label = str(mean_step) + \" Episodes\"\n",
    "    axarr[0].plot(x, mean_loss, label = label)\n",
    "    axarr[1].plot(x, mean_dists, label = label)\n",
    "    axarr[2].plot(x, mean_rewards, label = label)\n",
    "\n",
    "axarr[0].grid(True)\n",
    "axarr[0].set_title(title_str + 'Mean Loss') \n",
    "axarr[1].grid(True)\n",
    "axarr[1].set_title('Mean Distances from Goal')\n",
    "axarr[2].grid(True)\n",
    "axarr[2].set_title('Mean Rewards')\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "\n",
    "# axarr[1].plot(x, output['replays'])\n",
    "# axarr[1].set_title('Replay Loss')\n",
    "# axarr[2].plot(x2, output['reward_totals'])\n",
    "# axarr[2].set_title('Total Reward')\n",
    "# axarr[2].plot(x2, output['distances'])\n",
    "# axarr[2].set_title('Distance from Goal')\n",
    "\n",
    "file_str = str(training_game_size) + \"x\" + str(training_game_size) + \"_\" \n",
    "file_str += str(training_episodes) + \"_\" + str(steps) + \"_\" + str(len(hiddens))\n",
    "file_str += \"_\" + optimizer_str\n",
    "pl.legend()\n",
    "pl.plot()\n",
    "pl.savefig(\"hybrid_plots\" + \"_20_neurons_\" + file_str + \"_2.png\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cf37160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_game(training_game, n = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump( model, open( \"NaviGame_0.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_game.Navigator.move(7, 7, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
