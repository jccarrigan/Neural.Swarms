{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from reinforcement_training import *\n",
    "from notebook_game_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets train a DQN model!\n",
    "# make the model\n",
    "hiddens = [{\"size\":100,\"activation\":\"relu\"},\n",
    "           {\"size\":100,\"activation\":\"relu\"},\n",
    "           {\"size\":100,\"activation\":\"relu\"},\n",
    "          {\"size\":100,\"activation\":\"relu\"}]\n",
    "# make an optimizer\n",
    "from keras.optimizers import sgd, RMSprop, Adagrad, Adadelta, Adam\n",
    "# note to self: DON'T CHANGE THIS UNTIL YOU KNOW WE'RE LEARNING SOMETHING\n",
    "# optimizer = sgd(lr = 0.0001)\n",
    "# optimizer_str = \"SGD\"\n",
    "# optimizer = Adagrad()\n",
    "# optimizer_str = \"Adagrad\"\n",
    "# optimizer = RMSprop()\n",
    "# optimizer_str = \"RMSprop\"\n",
    "# optimizer = Adadelta()\n",
    "# optimizer_str = \"Adadelta\"\n",
    "optimizer = Adam()\n",
    "optimizer_str = \"Adam\"\n",
    "model = baseline_model(optimizer, hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the game for validating model\n",
    "test_game_size = 9\n",
    "test_game = ReinforcementNaviGame(test_game_size, test_game_size, model)\n",
    "test_game.setup()\n",
    "test_game.Navigator.move(x=1, y=0, relative = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_game.add_wall(start=(7,7), length=3, step=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e245be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_game.shift_goal()\n",
    "# test_game.Navigator.move(x=0, y=0, relative = False)\n",
    "animate_game(test_game, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the game for training model\n",
    "training_game_size = test_game_size\n",
    "training_game = ReinforcementNaviGame(training_game_size,\n",
    "                                training_game_size,\n",
    "                                model,\n",
    "                                tolerance = 1.3,\n",
    "                                goal_idle = 2)\n",
    "training_game.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 194221, Replay Loss: 0.482:  19%|█▉        | 194222/1000000 [7:55:42<32:40:19,  6.85it/s]   "
     ]
    }
   ],
   "source": [
    "training_episodes = 1000000\n",
    "steps = 10\n",
    "# train the model\n",
    "output = train_model(game = training_game,\n",
    "                model = model,\n",
    "                episodes = training_episodes,\n",
    "                steps = steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot learning info\n",
    "title_str = str(training_game_size) + \"x\" + str(training_game_size) + \" with \" \n",
    "title_str += str(training_episodes) + \" episodes, \" + str(steps) + \" steps per episode, & \"\n",
    "title_str += str(len(hiddens)) + \" hidden layers, optimized with \" + optimizer_str + \"\\n\"\n",
    "f, axarr = pl.subplots(3, 1, figsize = (10, 15), dpi = 300)\n",
    "# f.canvas.set_window_title(\"RL Loss, 100 eps w/ 50 steps, Look: 20\")\n",
    "mean_step = 10\n",
    "num_means = int(len(output['distances'])/mean_step/steps)\n",
    "\n",
    "for _, k in enumerate([1000, 10000, 100000]):\n",
    "    mean_step = k\n",
    "    mean_rewards = []\n",
    "    mean_dists = []\n",
    "    mean_loss = []\n",
    "    num_means = int(len(output['distances'])/mean_step/steps)\n",
    "    steps_per_mean = steps*mean_step\n",
    "    x = np.linspace(0, training_episodes, num_means)\n",
    "    for i in range(num_means):\n",
    "        mean_r = 0\n",
    "        mean_d = 0\n",
    "        mean_l = 0\n",
    "        for j in range(steps_per_mean):\n",
    "            mean_r += output['rewards'][j + i * steps_per_mean]\n",
    "            mean_d += output['distances'][j + i * steps_per_mean]\n",
    "            mean_l += output['loss'][j + i * steps_per_mean]\n",
    "        mean_r = mean_r / steps_per_mean\n",
    "        mean_d = mean_d / steps_per_mean\n",
    "        mean_l = mean_l / steps_per_mean\n",
    "        mean_rewards.append(mean_r)\n",
    "        mean_dists.append(mean_d)\n",
    "        mean_loss.append(mean_l)\n",
    "    label = str(mean_step) + \" Episodes\"\n",
    "    axarr[0].plot(x, mean_loss, label = label)\n",
    "    axarr[1].plot(x, mean_dists, label = label)\n",
    "    axarr[2].plot(x, mean_rewards, label = label)\n",
    "\n",
    "axarr[0].grid(True)\n",
    "axarr[0].set_title(title_str + 'Mean Loss') \n",
    "axarr[1].grid(True)\n",
    "axarr[1].set_title('Mean Distances from Goal')\n",
    "axarr[2].grid(True)\n",
    "axarr[2].set_title('Mean Rewards')\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "\n",
    "# axarr[1].plot(x, output['replays'])\n",
    "# axarr[1].set_title('Replay Loss')\n",
    "# axarr[2].plot(x2, output['reward_totals'])\n",
    "# axarr[2].set_title('Total Reward')\n",
    "# axarr[2].plot(x2, output['distances'])\n",
    "# axarr[2].set_title('Distance from Goal')\n",
    "\n",
    "file_str = str(training_game_size) + \"x\" + str(training_game_size) + \"_\" \n",
    "file_str += str(training_episodes) + \"_\" + str(steps) + \"_\" + str(len(hiddens))\n",
    "file_str += \"_\" + optimizer_str\n",
    "pl.legend()\n",
    "pl.plot()\n",
    "pl.savefig(\"rl_plots\" + \"_with_replay_50_neurons_per_later\" + file_str + \".png\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( model, open( \"NaviGame_0.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
