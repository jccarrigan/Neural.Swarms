{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from reinforcement_training import *\n",
    "from notebook_game_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets train a DQN model!\n",
    "# make the model\n",
    "hiddens = [{\"size\":50,\"activation\":\"relu\"}, \n",
    "          {\"size\":50,\"activation\":\"relu\"},\n",
    "          {\"size\":50,\"activation\":\"relu\"}]\n",
    "#           {\"size\":50,\"activation\":\"relu\"}]\n",
    "#           {\"size\":50,\"activation\":\"relu\"},\n",
    "#           {\"size\":50,\"activation\":\"relu\"},\n",
    "#           {\"size\":50,\"activation\":\"relu\"},\n",
    "#           {\"size\":50,\"activation\":\"relu\"}]\n",
    "# make an optimizer\n",
    "from keras.optimizers import sgd, RMSprop, Adagrad, Adadelta, Adam\n",
    "# note to self: DON'T CHANGE THIS UNTIL YOU KNOW WE'RE LEARNING SOMETHING\n",
    "# optimizer = sgd(lr = 0.0001)\n",
    "# optimizer_str = \"SGD\"\n",
    "optimizer = Adagrad()\n",
    "optimizer_str = \"Adagrad\"\n",
    "# optimizer = RMSprop()\n",
    "# optimizer_str = \"RMSprop\"\n",
    "# optimizer = Adadelta()\n",
    "# optimizer_str = \"Adadelta\"\n",
    "# optimizer = Adam()\n",
    "# optimizer_str = \"Adam\"\n",
    "model = baseline_model(optimizer, hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the game for training model\n",
    "training_game_size = 9\n",
    "training_game = ReinforcementNaviGame(training_game_size,\n",
    "                                training_game_size,\n",
    "                                model)\n",
    "training_game.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_episodes = 1000\n",
    "steps = 10\n",
    "# train the model\n",
    "output = train_model(game = training_game,\n",
    "                model = model,\n",
    "                episodes = training_episodes,\n",
    "                steps = steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot learning info\n",
    "title_str = str(training_game_size) + \"x\" + str(training_game_size) + \" with \" \n",
    "title_str += str(training_episodes) + \" episodes, \" + str(steps) + \" steps per episode, & \"\n",
    "title_str += str(len(hiddens)) + \" hidden layers, optimized with \" + optimizer_str + \"\\n\"\n",
    "f, axarr = pl.subplots(3, 1, figsize = (10, 15), dpi = 300)\n",
    "\n",
    "for _, k in enumerate([10, 50, 100]):\n",
    "    mean_step = k\n",
    "    mean_rewards = []\n",
    "    mean_dists = []\n",
    "    mean_loss = []\n",
    "    num_means = int(len(output['distances'])/mean_step/steps)\n",
    "    steps_per_mean = steps*mean_step\n",
    "    x = np.linspace(0, len(output['loss']), num_means)\n",
    "    for i in range(num_means):\n",
    "        mean_r = 0\n",
    "        mean_d = 0\n",
    "        mean_l = 0\n",
    "        for j in range(steps_per_mean):\n",
    "            mean_r += output['rewards'][j + i * steps_per_mean]\n",
    "            mean_d += output['distances'][j + i * steps_per_mean]\n",
    "            mean_l += output['loss'][j + i * steps_per_mean]\n",
    "        mean_r = mean_r / steps_per_mean\n",
    "        mean_d = mean_d / steps_per_mean\n",
    "        mean_l = mean_l / steps_per_mean\n",
    "        mean_rewards.append(mean_r)\n",
    "        mean_dists.append(mean_d)\n",
    "        mean_loss.append(mean_l)\n",
    "    label = str(mean_step) + \" Episodes\"\n",
    "    axarr[0].plot(x, mean_loss, label = label)\n",
    "    axarr[1].plot(x, mean_dists, label = label)\n",
    "    axarr[2].plot(x, mean_rewards, label = label)\n",
    "\n",
    "axarr[0].grid(True)\n",
    "axarr[0].set_title(title_str + 'Mean Loss') \n",
    "axarr[1].grid(True)\n",
    "axarr[1].set_title('Mean Distances from Goal')\n",
    "axarr[2].grid(True)\n",
    "axarr[2].set_title('Mean Rewards')\n",
    "f.subplots_adjust(hspace=0.2)\n",
    "\n",
    "# axarr[1].plot(x, output['replays'])\n",
    "# axarr[1].set_title('Replay Loss')\n",
    "# axarr[2].plot(x2, output['reward_totals'])\n",
    "# axarr[2].set_title('Total Reward')\n",
    "# axarr[2].plot(x2, output['distances'])\n",
    "# axarr[2].set_title('Distance from Goal')\n",
    "\n",
    "file_str = str(training_game_size) + \"x\" + str(training_game_size) + \"_\" \n",
    "file_str += str(training_episodes) + \"_\" + str(steps) + \"_\" + str(len(hiddens))\n",
    "file_str += \"_\" + optimizer_str\n",
    "pl.legend()\n",
    "pl.plot()\n",
    "pl.savefig(\"rl_plots\" + \"_with_replay_50_neurons_per_layer\" + file_str + \".png\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfn1EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd650e7bb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_game(training_game, n = 20, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"images/game_save/\"\n",
    "filenames = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "import imageio\n",
    "images = []\n",
    "filenames.sort()\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(mypath+filename))\n",
    "imageio.mimsave('game.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00_game_anim.png',\n",
       " '01_game_anim.png',\n",
       " '02_game_anim.png',\n",
       " '03_game_anim.png',\n",
       " '04_game_anim.png',\n",
       " '05_game_anim.png',\n",
       " '06_game_anim.png',\n",
       " '07_game_anim.png',\n",
       " '08_game_anim.png',\n",
       " '09_game_anim.png',\n",
       " '10_game_anim.png',\n",
       " '11_game_anim.png',\n",
       " '12_game_anim.png',\n",
       " '13_game_anim.png',\n",
       " '14_game_anim.png',\n",
       " '15_game_anim.png',\n",
       " '16_game_anim.png',\n",
       " '17_game_anim.png',\n",
       " '18_game_anim.png',\n",
       " '19_game_anim.png']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
